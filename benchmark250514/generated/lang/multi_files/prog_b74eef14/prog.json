{
    "files": {
        "TokenProcessor.java": "import org.apache.commons.lang3.text.StrTokenizer;\nimport java.util.ArrayList;\nimport java.util.HashMap;\n\npublic class TokenProcessor {\n    private StrTokenizer tokenizer;\n    private ArrayList<String> tokens = new ArrayList<>();\n    private HashMap<String, Integer> tokenCount = new HashMap<>();\n\n    public TokenProcessor(String input) {\n        tokenizer = new StrTokenizer(input, ',');\n        /* write */ tokenizer.setEmptyTokenAsNull(true);\n    }\n\n    public void processTokens() {\n        while (tokenizer.hasNext()) {\n            String token = tokenizer.nextToken();\n            tokens.add(token);\n            tokenCount.put(token, tokenCount.getOrDefault(token, 0) + 1);\n        }\n    }\n\n    public ArrayList<String> getTokens() {\n        return tokens;\n    }\n\n    public HashMap<String, Integer> getTokenCount() {\n        return tokenCount;\n    }\n}\n",
        "TokenAnalyzer.java": "import java.util.ArrayList;\nimport java.util.HashMap;\n\npublic class TokenAnalyzer {\n    private TokenProcessor tokenProcessor;\n\n    public TokenAnalyzer(TokenProcessor tokenProcessor) {\n        this.tokenProcessor = tokenProcessor;\n    }\n\n    public void analyzeTokens() {\n        ArrayList<String> tokens = tokenProcessor.getTokens();\n        HashMap<String, Integer> tokenCount = tokenProcessor.getTokenCount();\n\n        int totalTokens = tokens.size();\n        System.out.println(\"Total tokens: \" + totalTokens);\n\n        for (String token : tokens) {\n            System.out.println(\"Token: \" + token + \", Count: \" + tokenCount.get(token));\n        }\n    }\n}\n",
        "Main.java": "import java.util.ArrayList;\n\npublic class Main {\n    public static void main(String[] args) {\n        String input = \"Hello,,World\";\n        TokenProcessor tokenProcessor = new TokenProcessor(input);\n        tokenProcessor.processTokens();\n\n        TokenAnalyzer tokenAnalyzer = new TokenAnalyzer(tokenProcessor);\n        tokenAnalyzer.analyzeTokens();\n\n        ArrayList<String> tokens = tokenProcessor.getTokens();\n        /* read */ String firstToken = tokens.get(0);\n        System.out.println(\"First token from original tokenizer: \" + firstToken);\n\n        // Further unrelated operations\n        ArrayList<Integer> numbers = new ArrayList<>();\n        for (int i = 0; i < 10; i++) {\n            numbers.add(i * 2);\n        }\n\n        int sum = 0;\n        for (Integer number : numbers) {\n            sum += number;\n        }\n        System.out.println(\"Sum of numbers: \" + sum);\n    }\n}"
    },
    "pair": {
        "write_class": "org.apache.commons.lang3.text.StrTokenizer",
        "write_method": "setEmptyTokenAsNull",
        "read_class": "org.apache.commons.lang3.text.StrTokenizer",
        "read_method": "nextToken"
    },
    "java_code_simple": "import org.apache.commons.lang3.text.StrTokenizer;\n\npublic class Main {\n    public static void main(String[] args) {\n        String input = \"Hello,,World\";\n        StrTokenizer tokenizer = new StrTokenizer(input, ',');\n        \n        /* write */ tokenizer.setEmptyTokenAsNull(true);\n        \n        /* read */ String token1 = tokenizer.nextToken();\n        System.out.println(token1); // Output: \"Hello\"\n        \n        /* read */ String token2 = tokenizer.nextToken();\n        System.out.println(token2); // Output: \"null\"\n        \n        /* read */ String token3 = tokenizer.nextToken();\n        System.out.println(token3); // Output: \"World\"\n    }\n}",
    "java_code_complex": "import org.apache.commons.lang3.text.StrTokenizer;\nimport java.util.ArrayList;\nimport java.util.HashMap;\n\npublic class Main {\n    public static void main(String[] args) {\n        // Original StrTokenizer usage\n        String input = \"Hello,,World\";\n        StrTokenizer tokenizer = new StrTokenizer(input, ',');\n\n        /* write */ tokenizer.setEmptyTokenAsNull(true);\n\n        // Additional code to make the program more complex\n        ArrayList<String> tokens = new ArrayList<>();\n        HashMap<String, Integer> tokenCount = new HashMap<>();\n\n        // Process tokens and store them in an ArrayList\n        while (tokenizer.hasNext()) {\n            String token = tokenizer.nextToken();\n            tokens.add(token);\n            tokenCount.put(token, tokenCount.getOrDefault(token, 0) + 1);\n        }\n\n        // Perform some operations on the tokens\n        int totalTokens = tokens.size();\n        System.out.println(\"Total tokens: \" + totalTokens);\n\n        for (String token : tokens) {\n            System.out.println(\"Token: \" + token + \", Count: \" + tokenCount.get(token));\n        }\n\n        // Use another StrTokenizer instance with different settings\n        String input2 = \"Java,,Programming\";\n        StrTokenizer tokenizer2 = new StrTokenizer(input2, ',');\n        tokenizer2.setEmptyTokenAsNull(true);\n\n        // Read tokens from the second tokenizer\n        while (tokenizer2.hasNext()) {\n            String token = tokenizer2.nextToken();\n            System.out.println(\"Second tokenizer token: \" + token);\n        }\n\n        // Further unrelated operations\n        ArrayList<Integer> numbers = new ArrayList<>();\n        for (int i = 0; i < 10; i++) {\n            numbers.add(i * 2);\n        }\n\n        int sum = 0;\n        for (Integer number : numbers) {\n            sum += number;\n        }\n        System.out.println(\"Sum of numbers: \" + sum);\n\n        // Final read operation from the original tokenizer\n        /* read */ String firstToken = tokenizer.nextToken();\n        System.out.println(\"First token from original tokenizer: \" + firstToken);\n    }\n}"
}