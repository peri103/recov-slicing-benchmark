{
    "files": {
        "TokenProcessor.java": "import org.apache.commons.lang3.text.StrTokenizer;\nimport org.apache.commons.lang3.text.StrMatcher;\nimport java.util.ArrayList;\n\npublic class TokenProcessor {\n    private StrTokenizer tokenizer;\n    private ArrayList<String> tokens = new ArrayList<>();\n\n    public TokenProcessor(String input) {\n        tokenizer = new StrTokenizer(input);\n        /* write */ tokenizer.setTrimmerMatcher(StrMatcher.trimMatcher());\n    }\n\n    public void processTokens() {\n        while (tokenizer.hasNext()) {\n            tokens.add(tokenizer.nextToken());\n        }\n    }\n\n    public ArrayList<String> getTokens() {\n        return tokens;\n    }\n}\n",
        "TokenAnalyzer.java": "import java.util.ArrayList;\n\npublic class TokenAnalyzer {\n    private ArrayList<String> tokens;\n\n    public TokenAnalyzer(ArrayList<String> tokens) {\n        this.tokens = tokens;\n    }\n\n    public void analyzeTokens() {\n        for (String token : tokens) {\n            String upperToken = token.toUpperCase();\n            System.out.println(\"Uppercase Token: \" + upperToken);\n        }\n    }\n\n    public String getFirstToken() {\n        /* read */ return tokens.get(0);\n    }\n}\n",
        "Main.java": "public class Main {\n    public static void main(String[] args) {\n        // Process a string to tokenize and analyze\n        TokenProcessor processor = new TokenProcessor(\"  Hello, World!  \");\n        processor.processTokens();\n\n        // Analyze the tokens\n        TokenAnalyzer analyzer = new TokenAnalyzer(processor.getTokens());\n        analyzer.analyzeTokens();\n\n        // Get and print the first token\n        String firstToken = analyzer.getFirstToken();\n        System.out.println(\"First Token: \" + firstToken);\n    }\n}"
    },
    "pair": {
        "write_class": "org.apache.commons.lang3.text.StrTokenizer",
        "write_method": "setTrimmerMatcher",
        "read_class": "org.apache.commons.lang3.text.StrTokenizer",
        "read_method": "nextToken"
    },
    "java_code_simple": "import org.apache.commons.lang3.text.StrTokenizer;\nimport org.apache.commons.lang3.text.StrMatcher;\n\npublic class Main {\n    public static void main(String[] args) {\n        // Initialize the tokenizer with a sample string\n        StrTokenizer tokenizer = new StrTokenizer(\"  Hello, World!  \");\n        \n        // Use setTrimmerMatcher to trim the whitespace characters\n        /* write */ tokenizer.setTrimmerMatcher(StrMatcher.trimMatcher());\n        \n        // Read the first token after trimming\n        /* read */ String token = tokenizer.nextToken();\n        \n        // Print the token\n        System.out.println(token);\n    }\n}",
    "java_code_complex": "import org.apache.commons.lang3.text.StrTokenizer;\nimport org.apache.commons.lang3.text.StrMatcher;\nimport org.apache.commons.lang3.StringUtils;\nimport java.util.ArrayList;\n\npublic class Main {\n    public static void main(String[] args) {\n        // Initialize the tokenizer with a sample string\n        StrTokenizer tokenizer = new StrTokenizer(\"  Hello, World!  \");\n        \n        // Use setTrimmerMatcher to trim the whitespace characters\n        /* write */ tokenizer.setTrimmerMatcher(StrMatcher.trimMatcher());\n        \n        // Create a list to hold tokens\n        ArrayList<String> tokens = new ArrayList<>();\n        \n        // Add additional functionality: reverse a string\n        String reversedString = StringUtils.reverse(\"Hello, World!\");\n        System.out.println(\"Reversed: \" + reversedString);\n        \n        // Add tokens to the list while processing the tokenizer\n        while (tokenizer.hasNext()) {\n            tokens.add(tokenizer.nextToken());\n        }\n        \n        // Process the list of tokens and perform some operations\n        for (String token : tokens) {\n            // Convert each token to uppercase\n            String upperToken = token.toUpperCase();\n            System.out.println(\"Uppercase Token: \" + upperToken);\n        }\n        \n        // Read the first token after trimming\n        /* read */ String token = tokenizer.nextToken();\n        \n        // Print the token\n        System.out.println(\"First Token: \" + token);\n        \n        // Add more complex logic: concatenate all tokens\n        StringBuilder concatenatedTokens = new StringBuilder();\n        for (String token : tokens) {\n            concatenatedTokens.append(token).append(\" \");\n        }\n        System.out.println(\"Concatenated Tokens: \" + concatenatedTokens.toString().trim());\n    }\n}"
}