{
    "files": {
        "TokenProcessor.java": "import org.apache.commons.lang3.text.StrTokenizer;\nimport org.apache.commons.lang3.text.StrMatcher;\nimport java.util.ArrayList;\nimport java.util.HashMap;\n\npublic class TokenProcessor {\n    private StrTokenizer tokenizer;\n    private ArrayList<String> tokensList = new ArrayList<>();\n    private HashMap<String, Integer> tokenCountMap = new HashMap<>();\n\n    public TokenProcessor(String input) {\n        tokenizer = new StrTokenizer(input);\n        /* write */ tokenizer.setQuoteMatcher(StrMatcher.quoteMatcher());\n    }\n\n    public void processTokens() {\n        while (tokenizer.hasNext()) {\n            String token = tokenizer.nextToken();\n            tokensList.add(token);\n            tokenCountMap.put(token, tokenCountMap.getOrDefault(token, 0) + 1);\n        }\n    }\n\n    public ArrayList<String> getTokensList() {\n        return tokensList;\n    }\n\n    public HashMap<String, Integer> getTokenCountMap() {\n        return tokenCountMap;\n    }\n}\n",
        "Main.java": "import java.util.ArrayList;\nimport java.util.HashMap;\n\npublic class Main {\n    public static void main(String[] args) {\n        TokenProcessor processor = new TokenProcessor(\"Hello 'world'! This is a 'test'.\");\n        processor.processTokens();\n\n        ArrayList<String> tokensList = processor.getTokensList();\n        HashMap<String, Integer> tokenCountMap = processor.getTokenCountMap();\n\n        /* read */ String firstToken = tokensList.get(0);\n        System.out.println(\"First token: \" + firstToken);\n\n        System.out.println(\"All tokens and their counts:\");\n        for (String token : tokenCountMap.keySet()) {\n            System.out.println(\"Token: \" + token + \", Count: \" + tokenCountMap.get(token));\n        }\n    }\n}"
    },
    "pair": {
        "write_class": "org.apache.commons.lang3.text.StrTokenizer",
        "write_method": "setQuoteMatcher",
        "read_class": "org.apache.commons.lang3.text.StrTokenizer",
        "read_method": "nextToken"
    },
    "java_code_simple": "import org.apache.commons.lang3.text.StrTokenizer;\nimport org.apache.commons.lang3.text.StrMatcher;\n\npublic class Main {\n    public static void main(String[] args) {\n        // Initialize the StrTokenizer with a sample string\n        StrTokenizer tokenizer = new StrTokenizer(\"Hello 'world'!\");\n\n        // Set the quote matcher to handle quoted text\n        /* write */ tokenizer.setQuoteMatcher(StrMatcher.quoteMatcher());\n\n        // Read the next token from the tokenizer\n        /* read */ String token = tokenizer.nextToken();\n\n        // Print the token to verify the output\n        System.out.println(token);\n    }\n}",
    "java_code_complex": "import org.apache.commons.lang3.text.StrTokenizer;\nimport org.apache.commons.lang3.text.StrMatcher;\nimport java.util.ArrayList;\nimport java.util.HashMap;\n\npublic class Main {\n    public static void main(String[] args) {\n        // Initialize the StrTokenizer with a sample string\n        StrTokenizer tokenizer = new StrTokenizer(\"Hello 'world'! This is a 'test'.\");\n\n        // Create a map to store tokens and their counts\n        HashMap<String, Integer> tokenCountMap = new HashMap<>();\n\n        // Set the quote matcher to handle quoted text\n        /* write */ tokenizer.setQuoteMatcher(StrMatcher.quoteMatcher());\n\n        // Use another tokenizer for different string\n        StrTokenizer anotherTokenizer = new StrTokenizer(\"Sample 'text' for tokenizer.\");\n        anotherTokenizer.setQuoteMatcher(StrMatcher.quoteMatcher());\n\n        // Use an ArrayList to store tokens\n        ArrayList<String> tokensList = new ArrayList<>();\n\n        // Process all tokens using the first tokenizer\n        while (tokenizer.hasNext()) {\n            String token = tokenizer.nextToken();\n            tokensList.add(token);\n            tokenCountMap.put(token, tokenCountMap.getOrDefault(token, 0) + 1);\n        }\n\n        // Process all tokens using the second tokenizer\n        while (anotherTokenizer.hasNext()) {\n            String token = anotherTokenizer.nextToken();\n            tokensList.add(token);\n            tokenCountMap.put(token, tokenCountMap.getOrDefault(token, 0) + 1);\n        }\n\n        // Read the next token from the tokenizer\n        /* read */ String firstToken = tokensList.get(0);\n\n        // Print the first token to verify the output\n        System.out.println(\"First token: \" + firstToken);\n\n        // Print all tokens and their counts\n        System.out.println(\"All tokens and their counts:\");\n        for (String token : tokenCountMap.keySet()) {\n            System.out.println(\"Token: \" + token + \", Count: \" + tokenCountMap.get(token));\n        }\n    }\n}"
}